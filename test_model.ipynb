{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6836a9e1",
   "metadata": {},
   "source": [
    "# Tesla Top Posts Scraper\n",
    "\n",
    "Scrapt die 5 meist gevotetsten Tesla-Posts aus verschiedenen Subreddits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "355e4aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import re\n",
    "import time\n",
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "41244697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reddit API Setup - Verwendung der .env-Datei (wie in reddit_scraper.ipynb)\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import praw\n",
    "\n",
    "# Lade Umgebungsvariablen aus .env-Datei\n",
    "load_dotenv()\n",
    "\n",
    "# Reddit API Credentials aus .env-Datei\n",
    "reddit = praw.Reddit(\n",
    "    client_id=os.getenv(\"REDDIT_CLIENT_ID\"),\n",
    "    client_secret=os.getenv(\"REDDIT_CLIENT_SECRET\"),\n",
    "    user_agent=os.getenv(\"REDDIT_USER_AGENT\")\n",
    ")\n",
    "\n",
    "# SETTINGS\n",
    "keywords = [\n",
    "    'tesla',\n",
    "    'tsla', \n",
    "    'elon',\n",
    "    'musk'\n",
    "]\n",
    "\n",
    "# Subreddits zum Durchsuchen\n",
    "subreddits = [\n",
    "    'wallstreetbets',\n",
    "    'stocks', \n",
    "    'investing',\n",
    "    'SecurityAnalysis',\n",
    "    'StockMarket',\n",
    "    'ValueInvesting',\n",
    "    'technology',\n",
    "    'electricvehicles',\n",
    "    'teslamotors',\n",
    "    'elonmusk',\n",
    "    'GME',\n",
    "    'Aktien',\n",
    "    'teslainvestorsclub',\n",
    "    'wallstreetbetsGER'\n",
    "]\n",
    "\n",
    "# Anzahl Top Posts die am Ende zurückgegeben werden sollen\n",
    "TOP_POSTS_COUNT = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "306fc09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contains_tesla_keywords(text, keywords):\n",
    "    \"\"\"\n",
    "    Prüft ob Text Tesla-Keywords enthält\n",
    "    \"\"\"\n",
    "    if pd.isna(text) or text is None:\n",
    "        return False\n",
    "        \n",
    "    # Regex Pattern erstellen (Wortgrenzen für genauere Matches)\n",
    "    pattern = r'\\b(' + '|'.join(keywords) + r')\\b'\n",
    "    return bool(re.search(pattern, str(text), re.IGNORECASE))\n",
    "\n",
    "def get_top_tesla_posts(subreddits, keywords, top_count=5):\n",
    "    \"\"\"\n",
    "    Holt die Top Tesla-Posts aus allen Subreddits und gibt die meist gevotetsten zurück\n",
    "    \"\"\"\n",
    "    all_posts = []\n",
    "    \n",
    "    # Durchsuche alle Subreddits\n",
    "    for subreddit_name in subreddits:\n",
    "        try:\n",
    "            subreddit = reddit.subreddit(subreddit_name)\n",
    "            for post in subreddit.hot(limit=50):\n",
    "                # Prüfe Titel und Text auf Tesla Keywords\n",
    "                if (contains_tesla_keywords(post.title, keywords) or \n",
    "                    contains_tesla_keywords(post.selftext, keywords)):\n",
    "                    \n",
    "                    title = post.title\n",
    "                    text = post.selftext if post.selftext else ''\n",
    "                    full_text = f\"{title} {text}\".strip()\n",
    "                    \n",
    "                    all_posts.append({\n",
    "                        'title': title,\n",
    "                        'text': text,\n",
    "                        'score': post.score,\n",
    "                        'created': datetime.fromtimestamp(post.created_utc),\n",
    "                        'full_text': full_text\n",
    "                    })\n",
    "            # Kurze Pause zwischen Requests\n",
    "            time.sleep(1)\n",
    "        except Exception as e:\n",
    "            print(f\"Fehler beim Scrapen von r/{subreddit_name}: {e}\")\n",
    "    \n",
    "    # Sortiere nach Score (Upvotes) \n",
    "    all_posts.sort(key=lambda x: x['score'], reverse=True)\n",
    "    \n",
    "    # Nehme die Top N Posts\n",
    "    return pd.DataFrame(all_posts[:top_count])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e617113a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 Tesla posts\n",
      "1. [23889 upvotes] Tesla is the least-trusted car brand in America, survey find...\n",
      "2. [3396 upvotes] Grok is officially coming to Tesla next week at the latest....\n",
      "3. [2328 upvotes] Tesla Cybertruck Sales Fall Dramatically To Their Lowest Lev...\n",
      "4. [2095 upvotes] Elon pinned x: \"It is obvious with the insane spending of th...\n",
      "5. [1711 upvotes] Optimus handing out popcorn at the Tesla Diner...\n"
     ]
    }
   ],
   "source": [
    "tesla_df = get_top_tesla_posts(subreddits, keywords, TOP_POSTS_COUNT)\n",
    "\n",
    "if not tesla_df.empty:\n",
    "    print(f\"Found {len(tesla_df)} Tesla posts\")\n",
    "    for idx, row in tesla_df.iterrows():\n",
    "        print(f\"{idx+1}. [{row['score']} upvotes] {row['title'][:60]}...\")\n",
    "else:\n",
    "    print(\"No Tesla posts found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b9cc6f7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to data/tesla_top5_this_week.csv\n"
     ]
    }
   ],
   "source": [
    "# Export data\n",
    "if not tesla_df.empty:\n",
    "    os.makedirs('data', exist_ok=True)\n",
    "    filename = \"data/tesla_top5_this_week.csv\"\n",
    "    tesla_df.to_csv(filename, index=False)\n",
    "    print(f\"Data saved to {filename}\")\n",
    "else:\n",
    "    print(\"No data to export\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "933f8093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla Stock: $332.11 (+3.62, 1.1020%)\n"
     ]
    }
   ],
   "source": [
    "# Aktueller Tesla Aktienstand\n",
    "try:\n",
    "    import requests\n",
    "    \n",
    "    url = 'https://www.alphavantage.co/query?function=GLOBAL_QUOTE&symbol=TSLA&apikey=GR4S16Y4XV97PF9Z'\n",
    "    response = requests.get(url)\n",
    "    stock_data = response.json()\n",
    "    \n",
    "    if 'Global Quote' in stock_data:\n",
    "        quote = stock_data['Global Quote']\n",
    "        current_price = float(quote['05. price'])\n",
    "        change = float(quote['09. change'])\n",
    "        change_percent = quote['10. change percent'].rstrip('%')\n",
    "        \n",
    "        print(f\"Tesla Stock: ${current_price:.2f} ({change:+.2f}, {change_percent}%)\")\n",
    "        \n",
    "        if not tesla_df.empty:\n",
    "            tesla_df['tesla_stock_price'] = current_price\n",
    "            tesla_df['tesla_stock_change'] = change\n",
    "    else:\n",
    "        print(\"Error fetching Tesla stock price\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Stock API error: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
