{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ebaf965-9400-4a10-be91-35c652767473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.1+cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)  # Muss mindestens 2.6.0 sein\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "384543a0-0b70-43b0-acb7-87564f35a635",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name '_imaging' from 'PIL' (C:\\Users\\Tobia\\OneDrive\\HTW Uni\\5. Semester\\Unternehmenssoftware\\Projekt\\meme-stock-model\\venv\\Lib\\site-packages\\PIL\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AutoTokenizer, AutoModelForSequenceClassification\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvaderSentiment\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvaderSentiment\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SentimentIntensityAnalyzer\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfunctional\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m softmax\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\HTW Uni\\5. Semester\\Unternehmenssoftware\\Projekt\\meme-stock-model\\venv\\Lib\\site-packages\\transformers\\__init__.py:27\u001b[39m\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TYPE_CHECKING\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m# Check the dependencies satisfy the minimal versions required.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dependency_versions_check\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     29\u001b[39m     OptionalDependencyNotAvailable,\n\u001b[32m     30\u001b[39m     _LazyModule,\n\u001b[32m   (...)\u001b[39m\u001b[32m     49\u001b[39m     logging,\n\u001b[32m     50\u001b[39m )\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mimport_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m define_import_structure\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\HTW Uni\\5. Semester\\Unternehmenssoftware\\Projekt\\meme-stock-model\\venv\\Lib\\site-packages\\transformers\\dependency_versions_check.py:16\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Copyright 2020 The HuggingFace Team. All rights reserved.\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdependency_versions_table\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m deps\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mversions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m require_version, require_version_core\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# define which module versions we always want to check at run time\u001b[39;00m\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# (usually the ones defined in `install_requires` in setup.py)\u001b[39;00m\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# order specific notes:\u001b[39;00m\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# - tqdm must be checked before tokenizers\u001b[39;00m\n\u001b[32m     25\u001b[39m pkgs_to_check_at_runtime = [\n\u001b[32m     26\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mpython\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     27\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtqdm\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     37\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mpyyaml\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     38\u001b[39m ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\HTW Uni\\5. Semester\\Unternehmenssoftware\\Projekt\\meme-stock-model\\venv\\Lib\\site-packages\\transformers\\utils\\__init__.py:37\u001b[39m\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01margs_doc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     25\u001b[39m     ClassAttrs,\n\u001b[32m     26\u001b[39m     ClassDocstring,\n\u001b[32m   (...)\u001b[39m\u001b[32m     34\u001b[39m     set_min_indent,\n\u001b[32m     35\u001b[39m )\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackbone_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BackboneConfigMixin, BackboneMixin\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mchat_template_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DocstringParsingException, TypeHintParsingException, get_json_schema\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconstants\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD, IMAGENET_STANDARD_MEAN, IMAGENET_STANDARD_STD\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdoc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     40\u001b[39m     add_code_sample_docstrings,\n\u001b[32m     41\u001b[39m     add_end_docstrings,\n\u001b[32m   (...)\u001b[39m\u001b[32m     45\u001b[39m     replace_return_docstrings,\n\u001b[32m     46\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\HTW Uni\\5. Semester\\Unternehmenssoftware\\Projekt\\meme-stock-model\\venv\\Lib\\site-packages\\transformers\\utils\\chat_template_utils.py:41\u001b[39m\n\u001b[32m     38\u001b[39m     jinja2 = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_vision_available():\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mPIL\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mImage\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_torch_available():\n\u001b[32m     44\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Tensor\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\HTW Uni\\5. Semester\\Unternehmenssoftware\\Projekt\\meme-stock-model\\venv\\Lib\\site-packages\\PIL\\Image.py:90\u001b[39m\n\u001b[32m     81\u001b[39m MAX_IMAGE_PIXELS: \u001b[38;5;28mint\u001b[39m | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28mint\u001b[39m(\u001b[32m1024\u001b[39m * \u001b[32m1024\u001b[39m * \u001b[32m1024\u001b[39m // \u001b[32m4\u001b[39m // \u001b[32m3\u001b[39m)\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     85\u001b[39m     \u001b[38;5;66;03m# If the _imaging C module is not present, Pillow will not load.\u001b[39;00m\n\u001b[32m     86\u001b[39m     \u001b[38;5;66;03m# Note that other modules should not refer to _imaging directly;\u001b[39;00m\n\u001b[32m     87\u001b[39m     \u001b[38;5;66;03m# import Image and use the Image.core variable instead.\u001b[39;00m\n\u001b[32m     88\u001b[39m     \u001b[38;5;66;03m# Also note that Image.core is not a publicly documented interface,\u001b[39;00m\n\u001b[32m     89\u001b[39m     \u001b[38;5;66;03m# and should be considered private and subject to change.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _imaging \u001b[38;5;28;01mas\u001b[39;00m core\n\u001b[32m     92\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m __version__ != \u001b[38;5;28mgetattr\u001b[39m(core, \u001b[33m\"\u001b[39m\u001b[33mPILLOW_VERSION\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m     93\u001b[39m         msg = (\n\u001b[32m     94\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mThe _imaging extension was built for another version of Pillow or PIL:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     95\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCore version: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mgetattr\u001b[39m(core,\u001b[38;5;250m \u001b[39m\u001b[33m'\u001b[39m\u001b[33mPILLOW_VERSION\u001b[39m\u001b[33m'\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     96\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPillow version: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m__version__\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     97\u001b[39m         )\n",
      "\u001b[31mImportError\u001b[39m: cannot import name '_imaging' from 'PIL' (C:\\Users\\Tobia\\OneDrive\\HTW Uni\\5. Semester\\Unternehmenssoftware\\Projekt\\meme-stock-model\\venv\\Lib\\site-packages\\PIL\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from torch.nn.functional import softmax\n",
    "import torch\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558913b1-b93c-4177-abfe-e11cc8a4c274",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dbcea14b91f4a3cadd1596c264b6871",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/252 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0890caa66b6d4017b170b56947600f66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/758 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f09031a37d40472eab257b75c845c2f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a9038adf8fe4c3387bb942bd55ec5eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b841fa2e94048ecb2e0401b5b5be3e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === 1. Lade den originalen, bereits vorverarbeiteten DataFrame ===\n",
    "df = pd.read_csv('data/tesla_preprocessed.csv')\n",
    "\n",
    "# === 2. FinBERT vorbereiten ===\n",
    "finbert_model_name = \"ProsusAI/finbert\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(finbert_model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(finbert_model_name)\n",
    "\n",
    "model.eval()  # Inference-Modus\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# === 3. VADER vorbereiten ===\n",
    "vader_analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6912cad-b4e6-49b7-920e-4fe648ff80d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 4. Neue Spalten für Sentiment-Labels ===\n",
    "df['finbert_sentiment'] = ''\n",
    "df['finbert_score'] = 0.0\n",
    "df['vader_compound'] = 0.0\n",
    "df['vader_sentiment'] = ''\n",
    "\n",
    "# === 5. Texte zusammenfassen (z. B. Titel + Text) ===\n",
    "df['full_text'] = df['title'].fillna('') + ' ' + df['text'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18cd4dad-4d48-4bc8-9648-08481d4ba358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 6. Funktion: FinBERT Sentiment berechnen ===\n",
    "def get_finbert_sentiment(text):\n",
    "    try:\n",
    "        inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            probs = softmax(outputs.logits, dim=1).cpu().numpy()[0]\n",
    "            label_idx = probs.argmax()\n",
    "            labels = [\"negative\", \"neutral\", \"positive\"]\n",
    "            return labels[label_idx], float(probs[label_idx])\n",
    "    except Exception as e:\n",
    "        return \"error\", 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e3c588b-9452-469c-bf95-af17cf0626d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 7. Funktion: VADER Sentiment berechnen ===\n",
    "def get_vader_sentiment(text):\n",
    "    scores = vader_analyzer.polarity_scores(text)\n",
    "    compound = scores['compound']\n",
    "    label = 'positive' if compound > 0.05 else 'negative' if compound < -0.05 else 'neutral'\n",
    "    return compound, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cbc41c37-32fa-4c34-ac54-8b0035b988ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starte Sentimentanalyse...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                      | 4/13268 [00:00<43:16,  5.11it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a3e38974c5c40d7987b7027ddd93115",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 13268/13268 [35:41<00:00,  6.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentimentanalyse abgeschlossen!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# === 8. Sentimentberechnung durchführen ===\n",
    "print(\"Starte Sentimentanalyse...\")\n",
    "\n",
    "for i, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    text = row['full_text']\n",
    "    \n",
    "    # FinBERT\n",
    "    label, score = get_finbert_sentiment(text)\n",
    "    df.at[i, 'finbert_sentiment'] = label\n",
    "    df.at[i, 'finbert_score'] = score\n",
    "\n",
    "    # VADER\n",
    "    compound, vader_label = get_vader_sentiment(text)\n",
    "    df.at[i, 'vader_compound'] = compound\n",
    "    df.at[i, 'vader_sentiment'] = vader_label\n",
    "\n",
    "print(\"Sentimentanalyse abgeschlossen!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "983d91cf-3ca3-4d47-9653-275330278faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 10. Kombiniertes Sentiment berechnen ===\n",
    "\n",
    "def combine_sentiments(finbert, vader):\n",
    "    if \"error\" in [finbert, vader] or vader not in {\"positive\", \"neutral\", \"negative\"}:\n",
    "        return \"unknown\"\n",
    "    \n",
    "    if finbert == \"positive\" and vader == \"positive\":\n",
    "        return \"strong_positive\"\n",
    "    elif finbert == \"negative\" and vader == \"negative\":\n",
    "        return \"strong_negative\"\n",
    "    elif finbert == \"neutral\" and vader == \"neutral\":\n",
    "        return \"neutral\"\n",
    "    elif finbert == \"positive\" and vader == \"negative\":\n",
    "        return \"mixed\"\n",
    "    elif finbert == \"negative\" and vader == \"positive\":\n",
    "        return \"mixed\"\n",
    "    elif finbert == \"positive\" or vader == \"positive\":\n",
    "        return \"positive\"\n",
    "    elif finbert == \"negative\" or vader == \"negative\":\n",
    "        return \"negative\"\n",
    "    else:\n",
    "        return \"neutral\"\n",
    "\n",
    "# Neue Spalte erzeugen\n",
    "df['combined_sentiment'] = df.apply(lambda row: combine_sentiments(row['finbert_sentiment'], row['vader_sentiment']), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ccc6e1b4-7563-447b-8f38-79dc5bea1da2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Daten mit Sentiment gespeichert unter: data/tesla_sentiment.csv\n"
     ]
    }
   ],
   "source": [
    "# === 9. Ergebnisse speichern ===\n",
    "output_path = 'data/tesla_sentiment.csv'\n",
    "df.to_csv(output_path, index=False)\n",
    "print(f\"Daten mit Sentiment gespeichert unter: {output_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
