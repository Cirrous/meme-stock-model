{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6836a9e1",
   "metadata": {},
   "source": [
    "# Tesla Top Posts Scraper\n",
    "\n",
    "Scrapt die 5 meist gevotetsten Tesla-Posts aus verschiedenen Subreddits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "355e4aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import re\n",
    "import time\n",
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41244697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reddit API Setup - Verwendung der .env-Datei (wie in reddit_scraper.ipynb)\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import praw\n",
    "\n",
    "# Lade Umgebungsvariablen aus .env-Datei\n",
    "load_dotenv()\n",
    "\n",
    "# Reddit API Credentials aus .env-Datei\n",
    "reddit = praw.Reddit(\n",
    "    client_id=os.getenv(\"REDDIT_CLIENT_ID\"),\n",
    "    client_secret=os.getenv(\"REDDIT_CLIENT_SECRET\"),\n",
    "    user_agent=os.getenv(\"REDDIT_USER_AGENT\")\n",
    ")\n",
    "\n",
    "# SETTINGS\n",
    "keywords = [\n",
    "    'tesla',\n",
    "    'tsla', \n",
    "    'elon',\n",
    "    'musk'\n",
    "]\n",
    "\n",
    "# Subreddits zum Durchsuchen\n",
    "subreddits = [\n",
    "    'wallstreetbets',\n",
    "    'stocks', \n",
    "    'investing',\n",
    "    'SecurityAnalysis',\n",
    "    'StockMarket',\n",
    "    'ValueInvesting',\n",
    "    'technology',\n",
    "    'electricvehicles',\n",
    "    'teslamotors',\n",
    "    'elonmusk',\n",
    "    'GME',\n",
    "    'Aktien',\n",
    "    'teslainvestorsclub',\n",
    "    'wallstreetbetsGER'\n",
    "]\n",
    "\n",
    "# Anzahl Top Posts die am Ende zurückgegeben werden sollen\n",
    "TOP_POSTS_COUNT = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "306fc09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contains_tesla_keywords(text, keywords):\n",
    "    \"\"\"\n",
    "    Prüft ob Text Tesla-Keywords enthält\n",
    "    \"\"\"\n",
    "    if pd.isna(text) or text is None:\n",
    "        return False\n",
    "        \n",
    "    # Regex Pattern erstellen (Wortgrenzen für genauere Matches)\n",
    "    pattern = r'\\b(' + '|'.join(keywords) + r')\\b'\n",
    "    return bool(re.search(pattern, str(text), re.IGNORECASE))\n",
    "\n",
    "def get_top_tesla_posts(subreddits, keywords, top_count=5):\n",
    "    \"\"\"\n",
    "    Holt die Top Tesla-Posts aus allen Subreddits und gibt die meist gevotetsten zurück\n",
    "    \"\"\"\n",
    "    all_posts = []\n",
    "    \n",
    "    # Durchsuche alle Subreddits\n",
    "    for subreddit_name in subreddits:\n",
    "        try:\n",
    "            subreddit = reddit.subreddit(subreddit_name)\n",
    "            for post in subreddit.hot(limit=50):\n",
    "                # Prüfe Titel und Text auf Tesla Keywords\n",
    "                if (contains_tesla_keywords(post.title, keywords) or \n",
    "                    contains_tesla_keywords(post.selftext, keywords)):\n",
    "                    \n",
    "                    title = post.title\n",
    "                    text = post.selftext if post.selftext else ''\n",
    "                    full_text = f\"{title} {text}\".strip()\n",
    "                    \n",
    "                    all_posts.append({\n",
    "                        'title': title,\n",
    "                        'text': text,\n",
    "                        'score': post.score,\n",
    "                        'created': datetime.fromtimestamp(post.created_utc),\n",
    "                        'full_text': full_text\n",
    "                    })\n",
    "            # Kurze Pause zwischen Requests\n",
    "            time.sleep(1)\n",
    "        except Exception as e:\n",
    "            print(f\"Fehler beim Scrapen von r/{subreddit_name}: {e}\")\n",
    "    \n",
    "    # Sortiere nach Score (Upvotes) \n",
    "    all_posts.sort(key=lambda x: x['score'], reverse=True)\n",
    "    \n",
    "    # Nehme die Top N Posts\n",
    "    return pd.DataFrame(all_posts[:top_count])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e617113a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10 Tesla posts\n",
      "1. [3171 upvotes] Tesla’s earnings hit a new low, with largest revenue drop in...\n",
      "2. [2644 upvotes] Tesla faces ban from selling cars in California...\n",
      "3. [2097 upvotes] Elon pinned x: \"It is obvious with the insane spending of th...\n",
      "4. [2047 upvotes] Tesla falls out of trillion-dollar club after ugly earnings...\n",
      "5. [1815 upvotes] Optimus handing out popcorn at the Tesla Diner...\n",
      "6. [1567 upvotes] Elon crosses the Rubicon!...\n",
      "7. [1122 upvotes] It Looks Like the Tesla Model Y Refresh Has Bombed...\n",
      "8. [832 upvotes] Tesla Diner in Hollywood is OPEN!...\n",
      "9. [781 upvotes] Elon Musk drug testing report...\n",
      "10. [764 upvotes] What is Tesla testing...\n"
     ]
    }
   ],
   "source": [
    "tesla_df = get_top_tesla_posts(subreddits, keywords, TOP_POSTS_COUNT)\n",
    "\n",
    "if not tesla_df.empty:\n",
    "    print(f\"Found {len(tesla_df)} Tesla posts\")\n",
    "    for idx, row in tesla_df.iterrows():\n",
    "        print(f\"{idx+1}. [{row['score']} upvotes] {row['title'][:60]}...\")\n",
    "else:\n",
    "    print(\"No Tesla posts found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9cc6f7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to data/tesla_top10_this_week.csv\n"
     ]
    }
   ],
   "source": [
    "# Export data\n",
    "if not tesla_df.empty:\n",
    "    os.makedirs('data', exist_ok=True)\n",
    "    filename = \"data/tesla_top10_this_week.csv\"\n",
    "    tesla_df.to_csv(filename, index=False)\n",
    "    print(f\"Data saved to {filename}\")\n",
    "else:\n",
    "    print(\"No data to export\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
