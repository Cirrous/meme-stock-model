{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9601928",
   "metadata": {},
   "source": [
    "# Tesla Stock Prediction Pipeline\n",
    "\n",
    "Combines Reddit data, current stock price, and trained PyTorch model for real predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4da79ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "from datetime import datetime\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a11ab17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMWithPrice(\n",
       "  (lstm): LSTM(1027, 64, batch_first=True)\n",
       "  (fc): Linear(in_features=65, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "embedding_dim = 1027\n",
    "\n",
    "class LSTMWithPrice(nn.Module):\n",
    "    def __init__(self, input_dim=embedding_dim, hidden_dim=64, num_layers=1):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim + 1, 1)\n",
    "\n",
    "    def forward(self, x, lengths, price):\n",
    "        packed = nn.utils.rnn.pack_padded_sequence(\n",
    "            x, lengths.cpu(), batch_first=True, enforce_sorted=False\n",
    "        )\n",
    "        _, (hn, _) = self.lstm(packed)\n",
    "        h_cat = torch.cat([hn[-1], price], dim=1)\n",
    "        return self.fc(h_cat).squeeze(1)\n",
    "\n",
    "model = LSTMWithPrice(input_dim=embedding_dim, hidden_dim=64).to(device)\n",
    "model.load_state_dict(torch.load('models/best_model.pth', map_location=device))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd129b3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Using 10 Tesla posts for prediction\n"
     ]
    }
   ],
   "source": [
    "# Get current Tesla data from existing CSV\n",
    "try:\n",
    "    tesla_df = pd.read_csv('data/tesla_top10_this_week.csv', parse_dates=['created'])\n",
    "    \n",
    "    if not tesla_df.empty:\n",
    "        latest_post = tesla_df['created'].max()\n",
    "        hours_old = (datetime.now() - latest_post).total_seconds() / 3600\n",
    "        \n",
    "        if hours_old > 24:\n",
    "            print(\"‚ö†Ô∏è  Data is older than 24 hours - consider running test_model.ipynb first\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"‚ùå tesla_top5_this_week.csv not found\")\n",
    "    print(\"üí° Run test_model.ipynb first to generate current Tesla posts\")\n",
    "    \n",
    "    tesla_df = pd.DataFrame({\n",
    "        'title': ['Tesla stock discussion'],\n",
    "        'text': ['General Tesla market sentiment'],\n",
    "        'full_text': ['Tesla stock discussion General Tesla market sentiment'],\n",
    "        'score': [100],\n",
    "        'created': [datetime.now()]\n",
    "    })\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error loading CSV: {e}\")\n",
    "    tesla_df = pd.DataFrame({\n",
    "        'title': ['Tesla stock discussion'],\n",
    "        'text': ['General Tesla market sentiment'], \n",
    "        'full_text': ['Tesla stock discussion General Tesla market sentiment'],\n",
    "        'score': [100],\n",
    "        'created': [datetime.now()]\n",
    "    })\n",
    "\n",
    "print(f\"‚úÖ Using {len(tesla_df)} Tesla posts for prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de5209a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Calculating FinBERT sentiment scores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sentiment Analysis: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:01<00:00,  5.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Enhanced embeddings shape: (10, 1027)\n",
      "üìà Sentiment scores range: 0.005 to 0.893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate embeddings for current posts\n",
    "embedding_model = SentenceTransformer('mixedbread-ai/mxbai-embed-large-v1')\n",
    "\n",
    "texts = tesla_df['full_text'].tolist()\n",
    "embeddings = embedding_model.encode(texts)\n",
    "\n",
    "scores = tesla_df['score'].values\n",
    "scores_normalized = (scores - scores.min()) / (scores.max() - scores.min() + 1e-8)\n",
    "\n",
    "# FinBERT Sentiment Analysis (replacing text length)\n",
    "print(\"üìä Calculating FinBERT sentiment scores...\")\n",
    "finbert_model_name = \"ProsusAI/finbert\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(finbert_model_name)\n",
    "finbert_model = AutoModelForSequenceClassification.from_pretrained(finbert_model_name)\n",
    "finbert_model.to(device)\n",
    "finbert_model.eval()\n",
    "\n",
    "def compute_finbert_sentiment_scores(text_list):\n",
    "    results = []\n",
    "    for text in tqdm(text_list, desc=\"Sentiment Analysis\"):\n",
    "        inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "        inputs = {key: val.to(device) for key, val in inputs.items()}\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = finbert_model(**inputs)\n",
    "            probs = F.softmax(outputs.logits, dim=1)[0]\n",
    "        \n",
    "        positive = probs[2].item()\n",
    "        negative = probs[0].item()\n",
    "        sentiment_score = positive - negative  # Range: -1 to 1\n",
    "        results.append(sentiment_score)\n",
    "    \n",
    "    return np.array(results)\n",
    "\n",
    "sentiment_scores = compute_finbert_sentiment_scores(texts)\n",
    "# Normalize sentiment scores to [0, 1] range for consistency\n",
    "sentiment_normalized = (sentiment_scores + 1) / 2  # Convert from [-1,1] to [0,1]\n",
    "\n",
    "if not tesla_df.empty and 'created' in tesla_df.columns:\n",
    "    now = datetime.now()\n",
    "    recency_hours = [(now - pd.to_datetime(created)).total_seconds() / 3600 for created in tesla_df['created']]\n",
    "    max_hours = max(recency_hours) + 1e-8\n",
    "    recency_scores = [(max_hours - hours) / max_hours for hours in recency_hours]\n",
    "else:\n",
    "    recency_scores = [1.0] * len(texts)\n",
    "\n",
    "recency_scores = np.array(recency_scores)\n",
    "\n",
    "# Combine features: [embeddings (1024), score (1), sentiment (1), recency (1)] = 1027\n",
    "enhanced_embeddings = np.column_stack([\n",
    "    embeddings,\n",
    "    scores_normalized,\n",
    "    sentiment_normalized,  # FinBERT sentiment replacing text_length\n",
    "    recency_scores\n",
    "])\n",
    "\n",
    "print(f\"‚úÖ Enhanced embeddings shape: {enhanced_embeddings.shape}\")\n",
    "print(f\"üìà Sentiment scores range: {sentiment_scores.min():.3f} to {sentiment_scores.max():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "076956fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get current Tesla stock price\n",
    "try:\n",
    "    url = 'https://www.alphavantage.co/query?function=GLOBAL_QUOTE&symbol=TSLA&apikey=GR4S16Y4XV97PF9Z'\n",
    "    response = requests.get(url)\n",
    "    stock_data = response.json()\n",
    "    \n",
    "    if 'Global Quote' in stock_data:\n",
    "        quote = stock_data['Global Quote']\n",
    "        current_price = float(quote['05. price'])\n",
    "        change = float(quote['09. change'])\n",
    "        change_percent = quote['10. change percent'].rstrip('%')\n",
    "        trading_day = quote['07. latest trading day']\n",
    "    else:\n",
    "        current_price = 250.0\n",
    "        change = 0.0\n",
    "        change_percent = \"0.00\"\n",
    "        trading_day = datetime.now().strftime('%Y-%m-%d')\n",
    "        \n",
    "except Exception as e:\n",
    "    current_price = 250.0\n",
    "    change = 0.0\n",
    "    change_percent = \"0.00\"\n",
    "    trading_day = datetime.now().strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc13f91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make prediction\n",
    "with torch.no_grad():\n",
    "    embeddings_tensor = torch.tensor(enhanced_embeddings, dtype=torch.float32).unsqueeze(0)\n",
    "    lengths_tensor = torch.tensor([enhanced_embeddings.shape[0]], dtype=torch.long)\n",
    "    price_tensor = torch.tensor([[current_price]], dtype=torch.float32)\n",
    "    \n",
    "    embeddings_tensor = embeddings_tensor.to(device)\n",
    "    lengths_tensor = lengths_tensor.to(device)\n",
    "    price_tensor = price_tensor.to(device)\n",
    "    \n",
    "    predicted_price = model(embeddings_tensor, lengths_tensor, price_tensor).cpu().item()\n",
    "    \n",
    "    predicted_change = predicted_price - current_price\n",
    "    direction = \"steigt\" if predicted_change > 0 else \"f√§llt\"\n",
    "    \n",
    "    raw_confidence = min(abs(predicted_change) * 2, 1.0)\n",
    "    confidence = max(55, min(95, raw_confidence * 40 + 55))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a30918bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Tesla f√§llt (Confidence: 95%)\n"
     ]
    }
   ],
   "source": [
    "# Create prediction data for dashboard\n",
    "prediction_data = {\n",
    "    \"prediction\": {\n",
    "        \"direction\": direction,\n",
    "        \"confidence\": f\"{confidence:.0f}%\"\n",
    "    },\n",
    "    \"current_stock\": {\n",
    "        \"price\": current_price,\n",
    "        \"change\": change,\n",
    "        \"change_percent\": change_percent,\n",
    "        \"trading_day\": trading_day\n",
    "    },\n",
    "    \"reddit_posts\": [],\n",
    "    \"timestamp\": datetime.now().isoformat()\n",
    "}\n",
    "\n",
    "for _, post in tesla_df.iterrows():\n",
    "    positive_words = ['good', 'great', 'excellent', 'bullish', 'up', 'rise', 'profit', 'beat']\n",
    "    negative_words = ['bad', 'terrible', 'bearish', 'down', 'fall', 'loss', 'crash', 'drop']\n",
    "    \n",
    "    full_text = post.get('full_text', '')\n",
    "    if pd.isna(full_text) or full_text is None:\n",
    "        full_text = ''\n",
    "    \n",
    "    text_lower = str(full_text).lower()\n",
    "    pos_count = sum(1 for word in positive_words if word in text_lower)\n",
    "    neg_count = sum(1 for word in negative_words if word in text_lower)\n",
    "    \n",
    "    if pos_count > neg_count:\n",
    "        sentiment = \"positive\"\n",
    "    elif neg_count > pos_count:\n",
    "        sentiment = \"negative\"\n",
    "    else:\n",
    "        sentiment = \"neutral\"\n",
    "    \n",
    "    title = post.get('title', '')\n",
    "    if pd.isna(title) or title is None:\n",
    "        title = 'Tesla discussion'\n",
    "    title = str(title)\n",
    "    \n",
    "    text = post.get('text', '')\n",
    "    if pd.isna(text) or text is None:\n",
    "        text = ''\n",
    "    text = str(text)\n",
    "    \n",
    "    prediction_data[\"reddit_posts\"].append({\n",
    "        \"title\": title[:80] + \"...\" if len(title) > 80 else title,\n",
    "        \"score\": int(post['score']) if not pd.isna(post['score']) else 0,\n",
    "        \"sentiment\": sentiment,\n",
    "        \"text_preview\": text[:100] + \"...\" if len(text) > 100 else text\n",
    "    })\n",
    "\n",
    "os.makedirs('data', exist_ok=True)\n",
    "with open('data/latest_prediction.json', 'w') as f:\n",
    "    json.dump(prediction_data, f, indent=2)\n",
    "\n",
    "print(f\"üéØ Tesla {direction} (Confidence: {confidence:.0f}%)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
